{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports"
      ],
      "metadata": {
        "id": "U6H_FGmYflHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgR7ofqiez__",
        "outputId": "16eda2a1-e948-44c1-8a43-2d60c86d92c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gdown\n",
        "import gdown\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import  f1_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "BlwwMcKhfvN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive file ID and destination filename\n",
        "file_id = '15qfdoxXF_6QbHpIKX6cdLfhn5EqykrVz'\n",
        "destination = 'downloaded_file.zip'\n",
        "\n",
        "# Download the file from Google Drive\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)\n",
        "\n",
        "# Unpack the zip file\n",
        "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "    zip_ref.extractall('unzipped_content')\n",
        "\n",
        "print(\"Download and extraction complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICiCdwsQf5YR",
        "outputId": "74957f68-c7c5-4f36-a019-035caadd6442"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15qfdoxXF_6QbHpIKX6cdLfhn5EqykrVz\n",
            "From (redirected): https://drive.google.com/uc?id=15qfdoxXF_6QbHpIKX6cdLfhn5EqykrVz&confirm=t&uuid=b6ace14b-4909-4fe0-9727-64f71de65e47\n",
            "To: /content/downloaded_file.zip\n",
            "100%|██████████| 560M/560M [00:11<00:00, 48.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data information"
      ],
      "metadata": {
        "id": "x0LHRga3f6jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/unzipped_content/data/train.csv')\n",
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEhMrnOgf_rN",
        "outputId": "9061aff3-49cf-4a81-fad3-fbd28af252f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35332 entries, 0 to 35331\n",
            "Data columns (total 49 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Filename                35332 non-null  object\n",
            " 1   Identity                35332 non-null  int64 \n",
            " 2   Male                    35332 non-null  int64 \n",
            " 3   Young                   35332 non-null  int64 \n",
            " 4   Middle_Aged             35332 non-null  int64 \n",
            " 5   Senior                  35332 non-null  int64 \n",
            " 6   Asian                   35332 non-null  int64 \n",
            " 7   White                   35332 non-null  int64 \n",
            " 8   Black                   35332 non-null  int64 \n",
            " 9   Rosy_Cheeks             35332 non-null  int64 \n",
            " 10  Shiny_Skin              35332 non-null  int64 \n",
            " 11  Bald                    35332 non-null  int64 \n",
            " 12  Wavy_Hair               35332 non-null  int64 \n",
            " 13  Receding_Hairline       35332 non-null  int64 \n",
            " 14  Bangs                   35332 non-null  int64 \n",
            " 15  Sideburns               35332 non-null  int64 \n",
            " 16  Black_Hair              35332 non-null  int64 \n",
            " 17  Blond_Hair              35332 non-null  int64 \n",
            " 18  Brown_Hair              35332 non-null  int64 \n",
            " 19  Gray_Hair               35332 non-null  int64 \n",
            " 20  No_Beard                35332 non-null  int64 \n",
            " 21  Mustache                35332 non-null  int64 \n",
            " 22  5_o_Clock_Shadow        35332 non-null  int64 \n",
            " 23  Goatee                  35332 non-null  int64 \n",
            " 24  Oval_Face               35332 non-null  int64 \n",
            " 25  Square_Face             35332 non-null  int64 \n",
            " 26  Round_Face              35332 non-null  int64 \n",
            " 27  Double_Chin             35332 non-null  int64 \n",
            " 28  High_Cheekbones         35332 non-null  int64 \n",
            " 29  Chubby                  35332 non-null  int64 \n",
            " 30  Obstructed_Forehead     35332 non-null  int64 \n",
            " 31  Fully_Visible_Forehead  35332 non-null  int64 \n",
            " 32  Brown_Eyes              35332 non-null  int64 \n",
            " 33  Bags_Under_Eyes         35332 non-null  int64 \n",
            " 34  Bushy_Eyebrows          35332 non-null  int64 \n",
            " 35  Arched_Eyebrows         35332 non-null  int64 \n",
            " 36  Mouth_Closed            35332 non-null  int64 \n",
            " 37  Smiling                 35332 non-null  int64 \n",
            " 38  Big_Lips                35332 non-null  int64 \n",
            " 39  Big_Nose                35332 non-null  int64 \n",
            " 40  Pointy_Nose             35332 non-null  int64 \n",
            " 41  Heavy_Makeup            35332 non-null  int64 \n",
            " 42  Wearing_Hat             35332 non-null  int64 \n",
            " 43  Wearing_Earrings        35332 non-null  int64 \n",
            " 44  Wearing_Necktie         35332 non-null  int64 \n",
            " 45  Wearing_Lipstick        35332 non-null  int64 \n",
            " 46  No_Eyewear              35332 non-null  int64 \n",
            " 47  Eyeglasses              35332 non-null  int64 \n",
            " 48  Attractive              35332 non-null  int64 \n",
            "dtypes: int64(48), object(1)\n",
            "memory usage: 13.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess images"
      ],
      "metadata": {
        "id": "tNtAdCIbgDx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = '/content/unzipped_content/data/image_data'\n",
        "\n",
        "# mappig -1, 1 to 0, 1 to work easier\n",
        "train_data['Male'] = train_data['Male'].map({1: 1, -1: 0})\n",
        "\n",
        "age_columns = ['Young', 'Middle_Aged', 'Senior']\n",
        "for col in age_columns:\n",
        "    train_data[col] = train_data[col].map({1: 1, -1: 0})\n",
        "\n",
        "# also mapping here to be easier to work with\n",
        "def age_label(row):\n",
        "    if row['Young'] == 1:\n",
        "        return 0  # Young\n",
        "    elif row['Middle_Aged'] == 1:\n",
        "        return 1  # Middle_Aged\n",
        "    elif row['Senior'] == 1:\n",
        "        return 2  # Senior\n",
        "    else:\n",
        "        return -1  # Undefined\n",
        "\n",
        "# Removing records without label\n",
        "train_data['AgeLabel'] = train_data.apply(age_label, axis=1)\n",
        "train_data = train_data[train_data['AgeLabel'] != -1]\n",
        "\n",
        "X = train_data['Filename'].values\n",
        "y_gender = train_data['Male'].values.astype(int)\n",
        "y_age = train_data['AgeLabel'].values.astype(int)\n",
        "\n",
        "# Spliting into train and validation\n",
        "sss_gender = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=33)\n",
        "for train_idx, val_idx in sss_gender.split(X, y_gender):\n",
        "    X_train_gender, X_val_gender = X[train_idx], X[val_idx]\n",
        "    y_train_gender, y_val_gender = y_gender[train_idx], y_gender[val_idx]\n",
        "\n",
        "sss_age = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=33)\n",
        "for train_idx, val_idx in sss_age.split(X, y_age):\n",
        "    X_train_age, X_val_age = X[train_idx], X[val_idx]\n",
        "    y_train_age, y_val_age = y_age[train_idx], y_age[val_idx]\n",
        "\n",
        "ros_gender = RandomOverSampler(random_state=33)\n",
        "X_train_gender_res, y_train_gender_res = ros_gender.fit_resample(\n",
        "    X_train_gender.reshape(-1, 1), y_train_gender)\n",
        "X_train_gender_res = X_train_gender_res.flatten()\n",
        "\n",
        "ros_age = RandomOverSampler(random_state=33)\n",
        "X_train_age_res, y_train_age_res = ros_age.fit_resample(\n",
        "    X_train_age.reshape(-1, 1), y_train_age)\n",
        "X_train_age_res = X_train_age_res.flatten()\n",
        "\n",
        "def load_and_preprocess_image(filename):\n",
        "    image_path = tf.strings.join([image_directory, filename], separator=\"/\")\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [64, 64])\n",
        "    image = image / 255.0  # Normalize to [0,1]\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "87Md4PXogTSW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature engineering"
      ],
      "metadata": {
        "id": "UnyQMTcog4wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "def augment(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
        "    image = tf.image.random_hue(image, max_delta=0.02)\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image\n",
        "\n",
        "# preprocessing the images for gender training\n",
        "def prepare_dataset_gender(filenames, labels, training=True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(len(filenames))\n",
        "    dataset = dataset.map(lambda x, y: (load_and_preprocess_image(x), y),\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    if training:\n",
        "        dataset = dataset.map(lambda x, y: (augment(x), y),\n",
        "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# preprocessing the images for age training\n",
        "def prepare_dataset_age(filenames, labels, training=True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(len(filenames))\n",
        "    dataset = dataset.map(lambda x, y: (load_and_preprocess_image(x), y),\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    if training:\n",
        "        dataset = dataset.map(lambda x, y: (augment(x), y),\n",
        "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# calling the functions\n",
        "train_dataset_gender = prepare_dataset_gender(X_train_gender_res, y_train_gender_res, training=True)\n",
        "val_dataset_gender = prepare_dataset_gender(X_val_gender, y_val_gender, training=False)\n",
        "\n",
        "train_dataset_age = prepare_dataset_age(X_train_age_res, y_train_age_res, training=True)\n",
        "val_dataset_age = prepare_dataset_age(X_val_age, y_val_age, training=False)"
      ],
      "metadata": {
        "id": "mYfSbJrLg8dd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building CNNs"
      ],
      "metadata": {
        "id": "RtGq-pJWhW1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gender_model():\n",
        "    inputs = tf.keras.Input(shape=(64, 64, 3))\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def create_age_model():\n",
        "    inputs = tf.keras.Input(shape=(64, 64, 3))\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "gender_model = create_gender_model()\n",
        "age_model = create_age_model()"
      ],
      "metadata": {
        "id": "lTQ2vHObhY-n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss functions"
      ],
      "metadata": {
        "id": "ef11vJv8hg09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        epsilon = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        loss = -alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt)\n",
        "        return tf.reduce_mean(loss)\n",
        "    return loss\n",
        "def sparse_categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.int32)\n",
        "        y_true_one_hot = tf.one_hot(y_true, depth=3)\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1. - 1e-7)\n",
        "        cross_entropy = -y_true_one_hot * tf.math.log(y_pred)\n",
        "        weights = alpha * tf.pow(1 - y_pred, gamma) * y_true_one_hot\n",
        "        loss = weights * cross_entropy\n",
        "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "G1idtVbBhifZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building models"
      ],
      "metadata": {
        "id": "ZhGjFjyKhjew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# introducing models with respective loss functions\n",
        "# using adam optimizer to lower loss function\n",
        "gender_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                     loss=binary_focal_loss(),\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "age_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss=sparse_categorical_focal_loss(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# break after 5 epoch if no improvements happened\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train gender model\n",
        "history_gender = gender_model.fit(\n",
        "    train_dataset_gender,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset_gender,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Train age model\n",
        "history_age = age_model.fit(\n",
        "    train_dataset_age,\n",
        "    epochs=5,\n",
        "    validation_data=val_dataset_age,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylcta6sRhsVc",
        "outputId": "81fbc4ef-b7b4-4fc8-e3c4-074f3640556e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 256ms/step - accuracy: 0.7546 - loss: 0.1809 - val_accuracy: 0.8658 - val_loss: 0.1288\n",
            "Epoch 2/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 235ms/step - accuracy: 0.8505 - loss: 0.1249 - val_accuracy: 0.8779 - val_loss: 0.1050\n",
            "Epoch 3/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 219ms/step - accuracy: 0.8766 - loss: 0.1005 - val_accuracy: 0.8932 - val_loss: 0.0851\n",
            "Epoch 4/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 215ms/step - accuracy: 0.8976 - loss: 0.0802 - val_accuracy: 0.9042 - val_loss: 0.0679\n",
            "Epoch 5/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 212ms/step - accuracy: 0.9147 - loss: 0.0628 - val_accuracy: 0.9044 - val_loss: 0.0557\n",
            "Epoch 6/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 206ms/step - accuracy: 0.9257 - loss: 0.0497 - val_accuracy: 0.9154 - val_loss: 0.0438\n",
            "Epoch 7/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 210ms/step - accuracy: 0.9281 - loss: 0.0400 - val_accuracy: 0.9154 - val_loss: 0.0374\n",
            "Epoch 8/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 211ms/step - accuracy: 0.9338 - loss: 0.0329 - val_accuracy: 0.9245 - val_loss: 0.0318\n",
            "Epoch 9/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 213ms/step - accuracy: 0.9435 - loss: 0.0270 - val_accuracy: 0.9282 - val_loss: 0.0272\n",
            "Epoch 10/10\n",
            "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 208ms/step - accuracy: 0.9493 - loss: 0.0227 - val_accuracy: 0.9245 - val_loss: 0.0262\n",
            "Epoch 1/5\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 210ms/step - accuracy: 0.6411 - loss: 0.2393 - val_accuracy: 0.7839 - val_loss: 0.1601\n",
            "Epoch 2/5\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 208ms/step - accuracy: 0.7801 - loss: 0.1535 - val_accuracy: 0.8113 - val_loss: 0.1306\n",
            "Epoch 3/5\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 206ms/step - accuracy: 0.8334 - loss: 0.1176 - val_accuracy: 0.8447 - val_loss: 0.1014\n",
            "Epoch 4/5\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 206ms/step - accuracy: 0.8683 - loss: 0.0903 - val_accuracy: 0.8386 - val_loss: 0.0873\n",
            "Epoch 5/5\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 205ms/step - accuracy: 0.8873 - loss: 0.0698 - val_accuracy: 0.8498 - val_loss: 0.0739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test and Predict the model"
      ],
      "metadata": {
        "id": "hh3mgijphyzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_preds = gender_model.predict(val_dataset_gender)\n",
        "gender_preds_binary = (gender_preds > 0.5).astype(int).flatten()\n",
        "f1_gender = f1_score(y_val_gender, gender_preds_binary)\n",
        "print(f\"F1 Score for Gender: {f1_gender}\")\n",
        "print(\"Classification Report for Gender:\")\n",
        "print(classification_report(y_val_gender, gender_preds_binary))\n",
        "print(\"Confusion Matrix for Gender:\")\n",
        "print(confusion_matrix(y_val_gender, gender_preds_binary))\n",
        "\n",
        "age_preds = age_model.predict(val_dataset_age)\n",
        "age_preds_class = np.argmax(age_preds, axis=1)\n",
        "f1_age = f1_score(y_val_age, age_preds_class, average='weighted')\n",
        "print(f\"F1 Score for Age: {f1_age}\")\n",
        "print(\"Classification Report for Age:\")\n",
        "print(classification_report(y_val_age, age_preds_class))\n",
        "print(\"Confusion Matrix for Age:\")\n",
        "print(confusion_matrix(y_val_age, age_preds_class))\n"
      ],
      "metadata": {
        "id": "qZc9k-VDh1fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1fd494-e4d0-4274-bf17-43fba1724ec6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step\n",
            "F1 Score for Gender: 0.9092409240924092\n",
            "Classification Report for Gender:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.94      2605\n",
            "           1       0.88      0.93      0.91      1768\n",
            "\n",
            "    accuracy                           0.92      4373\n",
            "   macro avg       0.92      0.93      0.92      4373\n",
            "weighted avg       0.93      0.92      0.92      4373\n",
            "\n",
            "Confusion Matrix for Gender:\n",
            "[[2390  215]\n",
            " [ 115 1653]]\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step\n",
            "F1 Score for Age: 0.7983732824963466\n",
            "Classification Report for Age:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.80      0.87      3070\n",
            "           1       0.49      0.71      0.58       760\n",
            "           2       0.61      0.81      0.69       543\n",
            "\n",
            "    accuracy                           0.78      4373\n",
            "   macro avg       0.69      0.77      0.72      4373\n",
            "weighted avg       0.83      0.78      0.80      4373\n",
            "\n",
            "Confusion Matrix for Age:\n",
            "[[2447  474  149]\n",
            " [  86  543  131]\n",
            " [  25   80  438]]\n"
          ]
        }
      ]
    }
  ]
}